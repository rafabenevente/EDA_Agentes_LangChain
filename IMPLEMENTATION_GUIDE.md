# Guia de ImplementaÃ§Ã£o - EDA Agentes LangChain com Streamlit

## VisÃ£o Geral do Projeto

Este projeto implementa uma ferramenta de AnÃ¡lise ExploratÃ³ria de Dados (EDA) usando agentes LangChain integrados a uma interface Streamlit. A ferramenta permite que usuÃ¡rios faÃ§am perguntas em linguagem natural sobre arquivos CSV e recebam anÃ¡lises completas com visualizaÃ§Ãµes.

## Objetivos

- Criar agentes inteligentes capazes de analisar dados CSV
- Responder perguntas sobre tipos de dados, distribuiÃ§Ãµes, padrÃµes e anomalias
- Gerar visualizaÃ§Ãµes automÃ¡ticas para embasar as respostas
- Detectar correlaÃ§Ãµes e relaÃ§Ãµes entre variÃ¡veis
- Fornecer conclusÃµes baseadas nas anÃ¡lises realizadas
- Manter memÃ³ria das anÃ¡lises para conversaÃ§Ãµes contextuais

## Arquitetura do Sistema

### Componentes Principais

1. **Interface Streamlit**: Front-end para upload de arquivos e interaÃ§Ã£o com usuÃ¡rio
2. **Agentes LangChain**: Sistema inteligente de anÃ¡lise de dados
3. **Ferramentas Customizadas**: Tools especÃ­ficos para operaÃ§Ãµes de EDA
4. **Sistema de MemÃ³ria**: ManutenÃ§Ã£o do contexto das anÃ¡lises
5. **Motor de VisualizaÃ§Ãµes**: GeraÃ§Ã£o automÃ¡tica de grÃ¡ficos

### Stack TecnolÃ³gico

- **Framework Web**: Streamlit (>=1.28.0)
- **Agentes IA**: LangChain (>=0.0.350)
- **LLM Provider**: Google (Gemini Pro via langchain-google-genai)
- **ManipulaÃ§Ã£o de Dados**: pandas (>=2.1.0), numpy (>=1.24.0)
- **VisualizaÃ§Ãµes**: plotly (>=5.17.0), seaborn (>=0.12.0), matplotlib (>=3.7.0)
- **AnÃ¡lise EstatÃ­stica**: scipy (>=1.11.0), scikit-learn (>=1.3.0)
- **ConfiguraÃ§Ã£o**: python-dotenv (>=1.0.0)

## Estrutura do Projeto

```
EDA_Agentes_LangChain/
â”œâ”€â”€ .env                          # ConfiguraÃ§Ãµes do ambiente
â”œâ”€â”€ .env.example                  # Template de configuraÃ§Ãµes
â”œâ”€â”€ requirements.txt              # DependÃªncias do projeto
â”œâ”€â”€ environment.yml               # ConfiguraÃ§Ã£o do ambiente Conda
â”œâ”€â”€ app.py                        # AplicaÃ§Ã£o principal Streamlit
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py              # ConfiguraÃ§Ãµes centralizadas
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ eda_agent.py             # Agente principal de EDA
â”‚   â”œâ”€â”€ data_explorer_agent.py   # Agente explorador de dados
â”‚   â”œâ”€â”€ statistician_agent.py    # Agente estatÃ­stico
â”‚   â””â”€â”€ visualizer_agent.py      # Agente de visualizaÃ§Ãµes
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_analysis_tools.py   # Ferramentas de anÃ¡lise
â”‚   â”œâ”€â”€ visualization_tools.py   # Ferramentas de visualizaÃ§Ã£o
â”‚   â”œâ”€â”€ statistical_tools.py     # Ferramentas estatÃ­sticas
â”‚   â””â”€â”€ outlier_detection_tools.py # DetecÃ§Ã£o de anomalias
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py           # Carregamento de dados
â”‚   â”œâ”€â”€ memory_manager.py        # Gerenciamento de memÃ³ria
â”‚   â””â”€â”€ visualization_helpers.py # Helpers para visualizaÃ§Ãµes
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploads/                 # Arquivos CSV enviados pelos usuÃ¡rios
â”‚   â””â”€â”€ cache/                   # Cache de anÃ¡lises
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_agents.py           # Testes dos agentes
â”‚   â”œâ”€â”€ test_tools.py            # Testes das ferramentas
â”‚   â””â”€â”€ test_data/               # Dados de teste
â”‚       â””â”€â”€ sample.csv
â””â”€â”€ docs/
    â””â”€â”€ API.md                   # DocumentaÃ§Ã£o da API
```

## ImplementaÃ§Ã£o Detalhada

### 1. ConfiguraÃ§Ã£o do Ambiente

#### Arquivo .env
```bash
# Google AI Configuration
GOOGLE_API_KEY=your_google_api_key_here
GOOGLE_MODEL=gemini-pro

# Streamlit Configuration
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=localhost

# Data Configuration
MAX_FILE_SIZE_MB=100
ALLOWED_EXTENSIONS=csv

# Cache Configuration
ENABLE_CACHE=true
CACHE_TTL_SECONDS=3600

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/eda_agent.log
```

#### Arquivo environment.yml
```yaml
name: eda_lang
channels:
  - conda-forge
  - defaults
dependencies:
  - python=3.11
  - pip
  - pip:
    - streamlit>=1.28.0
    - langchain>=0.0.350
    - langchain-google-genai>=0.0.5
    - pandas>=2.1.0
    - numpy>=1.24.0
    - plotly>=5.17.0
    - seaborn>=0.12.0
    - matplotlib>=3.7.0
    - scipy>=1.11.0
    - scikit-learn>=1.3.0
    - python-dotenv>=1.0.0
    - streamlit-plotly-events>=0.0.6
    - pytest>=7.4.0
    - black>=23.0.0
    - flake8>=6.0.0
```

### 2. Agente Principal (agents/eda_agent.py)

```python
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.memory import ConversationBufferWindowMemory
from langchain.prompts import ChatPromptTemplate
from tools.data_analysis_tools import get_data_analysis_tools
from tools.visualization_tools import get_visualization_tools
from tools.statistical_tools import get_statistical_tools
from tools.outlier_detection_tools import get_outlier_detection_tools

class EDAAgent:
    def __init__(self, google_api_key: str):
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-pro",
            google_api_key=google_api_key,
            temperature=0.1
        )
        self.memory = ConversationBufferWindowMemory(
            k=10,
            memory_key="chat_history",
            return_messages=True
        )
        
        # Combinar todas as ferramentas
        self.tools = (
            get_data_analysis_tools() +
            get_visualization_tools() +
            get_statistical_tools() +
            get_outlier_detection_tools()
        )
        
        self.agent_executor = self._create_agent()
    
    def _create_agent(self) -> AgentExecutor:
        prompt = ChatPromptTemplate.from_messages([
            ("system", """VocÃª Ã© um especialista em AnÃ¡lise ExploratÃ³ria de Dados (EDA).
            Sua funÃ§Ã£o Ã© analisar datasets CSV e responder perguntas sobre:
            - Tipos de dados e distribuiÃ§Ãµes
            - PadrÃµes e tendÃªncias
            - Anomalias e outliers
            - RelaÃ§Ãµes entre variÃ¡veis
            - ConclusÃµes e insights
            
            Sempre use as ferramentas disponÃ­veis para gerar visualizaÃ§Ãµes que embasem suas respostas.
            Mantenha o contexto das anÃ¡lises anteriores na conversa."""),
            ("human", "{input}"),
            ("placeholder", "{agent_scratchpad}")
        ])
        
        agent = create_openai_tools_agent(self.llm, self.tools, prompt)
        return AgentExecutor(
            agent=agent,
            tools=self.tools,
            memory=self.memory,
            verbose=True,
            max_iterations=10
        )
    
    def analyze(self, query: str, dataframe=None) -> dict:
        if dataframe is not None:
            # Armazenar dataframe no contexto
            self.memory.chat_memory.add_user_message(f"Dataset carregado com {len(dataframe)} linhas e {len(dataframe.columns)} colunas")
        
        response = self.agent_executor.invoke({"input": query})
        return response
```

### 3. Ferramentas de AnÃ¡lise (tools/data_analysis_tools.py)

```python
from langchain.tools import tool
import pandas as pd
import numpy as np
from typing import List, Dict, Any

@tool
def describe_dataset(dataframe: pd.DataFrame) -> Dict[str, Any]:
    """Fornece descriÃ§Ã£o estatÃ­stica completa do dataset"""
    return {
        "shape": dataframe.shape,
        "columns": list(dataframe.columns),
        "dtypes": dataframe.dtypes.to_dict(),
        "missing_values": dataframe.isnull().sum().to_dict(),
        "numeric_summary": dataframe.describe().to_dict(),
        "memory_usage": dataframe.memory_usage(deep=True).sum()
    }

@tool
def analyze_data_types(dataframe: pd.DataFrame) -> Dict[str, List[str]]:
    """Analisa e categoriza os tipos de dados das colunas"""
    numeric_cols = dataframe.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = dataframe.select_dtypes(include=['object', 'category']).columns.tolist()
    datetime_cols = dataframe.select_dtypes(include=['datetime64']).columns.tolist()
    boolean_cols = dataframe.select_dtypes(include=['bool']).columns.tolist()
    
    return {
        "numeric": numeric_cols,
        "categorical": categorical_cols,
        "datetime": datetime_cols,
        "boolean": boolean_cols
    }

def get_data_analysis_tools() -> List:
    return [describe_dataset, analyze_data_types]
```

### 4. Interface Streamlit (app.py)

```python
import streamlit as st
import pandas as pd
from config.settings import load_settings
from agents.eda_agent import EDAAgent
from utils.data_loader import DataLoader
from utils.memory_manager import MemoryManager

def main():
    st.set_page_config(
        page_title="EDA Agentes LangChain",
        page_icon="ðŸ“Š",
        layout="wide"
    )
    
    st.title("ðŸ¤– Assistente Inteligente de EDA")
    st.markdown("FaÃ§a perguntas sobre seus dados em linguagem natural!")
    
    # ConfiguraÃ§Ãµes
    settings = load_settings()
    
    # Inicializar agente
    if 'eda_agent' not in st.session_state:
        st.session_state.eda_agent = EDAAgent(settings.GOOGLE_API_KEY)
    
    # Upload de arquivo
    uploaded_file = st.file_uploader(
        "Escolha um arquivo CSV",
        type=['csv'],
        help="Envie um arquivo CSV para anÃ¡lise"
    )
    
    if uploaded_file is not None:
        # Carregar dados
        dataloader = DataLoader()
        df = dataloader.load_csv(uploaded_file)
        
        if df is not None:
            st.success(f"Arquivo carregado: {df.shape[0]} linhas, {df.shape[1]} colunas")
            
            # Mostrar preview dos dados
            with st.expander("Preview dos Dados"):
                st.dataframe(df.head())
            
            # Interface de chat
            if 'messages' not in st.session_state:
                st.session_state.messages = []
            
            # Mostrar histÃ³rico de mensagens
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])
            
            # Input do usuÃ¡rio
            if prompt := st.chat_input("FaÃ§a uma pergunta sobre os dados..."):
                st.session_state.messages.append({"role": "user", "content": prompt})
                with st.chat_message("user"):
                    st.markdown(prompt)
                
                # Resposta do agente
                with st.chat_message("assistant"):
                    with st.spinner("Analisando..."):
                        response = st.session_state.eda_agent.analyze(prompt, df)
                        st.markdown(response["output"])
                        
                        # Adicionar visualizaÃ§Ãµes se houver
                        if "visualizations" in response:
                            for viz in response["visualizations"]:
                                st.plotly_chart(viz, use_container_width=True)
                
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": response["output"]
                })

if __name__ == "__main__":
    main()
```

## Testes de Funcionalidade

### 1. Teste dos Agentes (tests/test_agents.py)

```python
import pytest
import pandas as pd
from agents.eda_agent import EDAAgent
import os

class TestEDAAgent:
    def setup_method(self):
        self.agent = EDAAgent(os.getenv("GOOGLE_API_KEY"))
        self.sample_df = pd.read_csv("tests/test_data/sample.csv")
    
    def test_agent_initialization(self):
        assert self.agent is not None
        assert len(self.agent.tools) > 0
    
    def test_basic_analysis(self):
        response = self.agent.analyze(
            "Descreva os dados bÃ¡sicos deste dataset",
            self.sample_df
        )
        assert "output" in response
        assert len(response["output"]) > 0
    
    def test_correlation_analysis(self):
        response = self.agent.analyze(
            "Quais sÃ£o as correlaÃ§Ãµes entre as variÃ¡veis numÃ©ricas?",
            self.sample_df
        )
        assert "correlaÃ§Ã£o" in response["output"].lower()
```

### 2. Teste das Ferramentas (tests/test_tools.py)

```python
import pytest
import pandas as pd
from tools.data_analysis_tools import describe_dataset, analyze_data_types

class TestDataAnalysisTools:
    def setup_method(self):
        self.df = pd.DataFrame({
            'numeric_col': [1, 2, 3, 4, 5],
            'categorical_col': ['A', 'B', 'C', 'A', 'B'],
            'date_col': pd.date_range('2023-01-01', periods=5)
        })
    
    def test_describe_dataset(self):
        result = describe_dataset.func(self.df)
        assert result["shape"] == (5, 3)
        assert "numeric_col" in result["columns"]
    
    def test_analyze_data_types(self):
        result = analyze_data_types.func(self.df)
        assert "numeric_col" in result["numeric"]
        assert "categorical_col" in result["categorical"]
```

## Comandos de InstalaÃ§Ã£o e ExecuÃ§Ã£o

### ConfiguraÃ§Ã£o do Ambiente

```powershell
# Ativar ambiente conda
conda activate eda_lang

# Instalar dependÃªncias
conda env update -f environment.yml

# Instalar dependÃªncias adicionais via pip
pip install -r requirements.txt

# Configurar variÃ¡veis de ambiente
cp .env.example .env
# Editar .env com suas configuraÃ§Ãµes
```

### ExecuÃ§Ã£o da AplicaÃ§Ã£o

```powershell
# Ativar ambiente
conda activate eda_lang

# Executar aplicaÃ§Ã£o Streamlit
streamlit run app.py

# Executar testes
pytest tests/ -v

# FormataÃ§Ã£o de cÃ³digo
black .

# Linting
flake8 .
```

## Checklist de ImplementaÃ§Ã£o

### Fase 1: Setup Inicial
- [ ] Configurar ambiente conda `eda_lang`
- [ ] Criar estrutura de pastas
- [ ] Configurar arquivos de dependÃªncias
- [ ] Implementar configuraÃ§Ãµes bÃ¡sicas (.env)

### Fase 2: Agentes e Ferramentas
- [ ] Implementar agente principal EDAAgent
- [ ] Criar ferramentas de anÃ¡lise de dados
- [ ] Implementar ferramentas de visualizaÃ§Ã£o
- [ ] Desenvolver sistema de memÃ³ria

### Fase 3: Interface Streamlit
- [ ] Criar interface de upload de arquivos
- [ ] Implementar chat interface
- [ ] Integrar visualizaÃ§Ãµes
- [ ] Adicionar cache e otimizaÃ§Ãµes

### Fase 4: Testes e ValidaÃ§Ã£o
- [ ] Escrever testes unitÃ¡rios
- [ ] Criar dados de teste
- [ ] Testar com datasets reais
- [ ] Validar performance

### Fase 5: Deploy e DocumentaÃ§Ã£o
- [ ] Preparar para deploy
- [ ] Documentar API
- [ ] Criar guia do usuÃ¡rio
- [ ] Otimizar para produÃ§Ã£o

## ConsideraÃ§Ãµes de Performance

- Implementar cache para anÃ¡lises repetitivas
- Limitar tamanho de arquivos CSV (100MB)
- Usar lazy loading para visualizaÃ§Ãµes complexas
- Otimizar consultas ao LLM com prompts eficientes

## PrÃ³ximos Passos

1. Implementar a estrutura bÃ¡sica seguindo este guia
2. Testar com datasets pequenos primeiro
3. Expandir funcionalidades gradualmente
4. Otimizar baseado no feedback dos usuÃ¡rios
5. Implementar features avanÃ§adas como ML automÃ¡tico